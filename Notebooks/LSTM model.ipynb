{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class WindowGenerator:\n",
    "    \"\"\"A utility class for generating windows of time-series data suitable for\n",
    "    training machine learning models. Provides functionalities for plotting and\n",
    "    visualizing data windows and predictions.\"\"\"\n",
    "\n",
    "    def __init__(self, input_width, label_width, shift, train_df, val_df, test_df, label_columns=[\"Patv\"]):\n",
    "        # Store raw data\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # List of columns to be used as labels for prediction\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        # Mapping from column names to their indices\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "\n",
    "        # Parameters for windowing the data\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        # Total size of the window\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        # Indices for the input and label data within the window\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def split_window(self, features):\n",
    "        \"\"\"Splits a batch of data into input features and labels.\"\"\"\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns:\n",
    "            labels = tf.stack([labels[:, :, self.column_indices[name]] for name in self.label_columns], axis=-1)\n",
    "\n",
    "        # Ensure the inputs and labels have the right shapes\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def plot(self, model=None, plot_col=\"Patv\", max_subplots=1):\n",
    "        \"\"\"Visualize the window of input data and labels.\n",
    "\n",
    "        If a model is provided, it plots its predictions as well.\n",
    "\n",
    "        Args:\n",
    "            model (tf.keras.Model, optional): Model to make predictions.\n",
    "            plot_col (str, optional): Column name to plot. Defaults to \"Patv\".\n",
    "            max_subplots (int, optional): Maximum number of subplots to display. Defaults to 1.\n",
    "        \"\"\"\n",
    "        inputs, labels = self.example\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n + 1)\n",
    "            plt.title(\"Inputs (past) vs Labels (future predictions)\", fontsize=FONT_SIZE_TITLE)\n",
    "            plt.ylabel(f\"{plot_col} (normalized)\", fontsize=FONT_SIZE_AXES)\n",
    "            plt.plot(\n",
    "                self.input_indices,\n",
    "                inputs[n, :, plot_col_index],\n",
    "                color=\"green\",\n",
    "                linestyle=\"--\",\n",
    "                label=\"Inputs\",\n",
    "                marker=\"o\",\n",
    "                markersize=10,\n",
    "                zorder=-10,\n",
    "            )\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.plot(\n",
    "                self.label_indices,\n",
    "                labels[n, :, label_col_index],\n",
    "                color=\"orange\",\n",
    "                linestyle=\"--\",\n",
    "                label=\"Labels\",\n",
    "                markersize=10,\n",
    "                marker=\"o\"\n",
    "            )\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(\n",
    "                    self.label_indices,\n",
    "                    predictions[n, :, label_col_index],\n",
    "                    marker=\"*\",\n",
    "                    edgecolors=\"k\",\n",
    "                    label=\"Predictions\",\n",
    "                    c=\"pink\",\n",
    "                    s=64,\n",
    "                )\n",
    "            plt.legend(fontsize=FONT_SIZE_TICKS)\n",
    "        plt.tick_params(axis=\"both\", labelsize=FONT_SIZE_TICKS)\n",
    "        plt.xlabel(\"Timestep\", fontsize=FONT_SIZE_AXES)\n",
    "\n",
    "    def plot_long(\n",
    "        self,\n",
    "        model,\n",
    "        data_splits,\n",
    "        plot_col=\"Patv\",\n",
    "        time_steps_future=1,\n",
    "        baseline_mae=None,\n",
    "    ):\n",
    "        \"\"\"Plot long term predictions against real values for the test split.\n",
    "\n",
    "        Args:\n",
    "            model (tf.keras.Model): Model to make predictions.\n",
    "            data_splits: Object containing training mean and standard deviation.\n",
    "            plot_col (str, optional): Column name to plot. Defaults to \"Patv\".\n",
    "            time_steps_future (int, optional): Number of time steps to look into the future.\n",
    "            baseline_mae (float, optional): Baseline mean absolute error for comparison.\n",
    "        \"\"\"\n",
    "        train_mean, train_std = data_splits.train_mean, data_splits.train_std\n",
    "        self.test_size = len(self.test_df)\n",
    "        self.test_data = self.make_test_dataset(self.test_df, self.test_size)\n",
    "\n",
    "        inputs, labels = next(iter(self.test_data))\n",
    "\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "\n",
    "        plt.ylabel(f\"{plot_col} (kW)\", fontsize=FONT_SIZE_AXES)\n",
    "\n",
    "        if self.label_columns:\n",
    "            label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "        else:\n",
    "            label_col_index = plot_col_index\n",
    "\n",
    "        labels = (labels * train_std.Patv) + train_mean.Patv\n",
    "\n",
    "        upper = 24 - (time_steps_future - 1)\n",
    "        lower = self.label_indices[-1] - upper\n",
    "        self.label_indices_long = self.test_df.index[lower:-upper]\n",
    "\n",
    "        plt.plot(\n",
    "            self.label_indices_long[:],\n",
    "            labels[:, time_steps_future - 1, label_col_index][:],\n",
    "            label=\"Labels\",\n",
    "            c=\"green\",\n",
    "        )\n",
    "\n",
    "        if model is not None:\n",
    "            predictions = model(inputs)\n",
    "            predictions = (predictions * train_std.Patv) + train_mean.Patv\n",
    "            predictions_for_timestep = predictions[\n",
    "                :, time_steps_future - 1, label_col_index\n",
    "            ][:]\n",
    "            predictions_for_timestep = tf.nn.relu(predictions_for_timestep).numpy()\n",
    "            plt.plot(\n",
    "                self.label_indices_long[:],\n",
    "                predictions_for_timestep,\n",
    "                label=\"Predictions\",\n",
    "                c=\"orange\",\n",
    "                linewidth=3,\n",
    "            )\n",
    "            plt.legend(fontsize=FONT_SIZE_TICKS)\n",
    "            _, mae = compute_metrics(\n",
    "                labels[:, time_steps_future - 1, label_col_index][:],\n",
    "                predictions_for_timestep,\n",
    "            )\n",
    "\n",
    "            if baseline_mae is None:\n",
    "                baseline_mae = mae\n",
    "\n",
    "            print(\n",
    "                f\"\\nMean Absolute Error (kW): {mae:.2f} for forecast.\\n\\nImprovement over random baseline: {100*((baseline_mae -mae)/baseline_mae):.2f}%\"\n",
    "            )\n",
    "        plt.title(\"Predictions vs Real Values for Test Split\", fontsize=FONT_SIZE_TITLE)\n",
    "        plt.xlabel(\"Date\", fontsize=FONT_SIZE_AXES)\n",
    "        plt.tick_params(axis=\"both\", labelsize=FONT_SIZE_TICKS)\n",
    "        return mae\n",
    "\n",
    "    def make_test_dataset(self, data, bs):\n",
    "        \"\"\"Prepare a TensorFlow dataset suitable for model evaluation.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): Data to be windowed.\n",
    "            bs (int): Batch size.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: Windowed dataset.\n",
    "        \"\"\"\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=False,\n",
    "            batch_size=bs,\n",
    "        )\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        \"\"\"Prepare a TensorFlow dataset suitable for model training/validation.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): Data to be windowed.\n",
    "\n",
    "        Returns:\n",
    "            tf.data.Dataset: Windowed dataset.\n",
    "        \"\"\"\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32,\n",
    "        )\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        \"\"\"tf.data.Dataset: Returns a windowed dataset for training.\"\"\"\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        \"\"\"tf.data.Dataset: Returns a windowed dataset for validation.\"\"\"\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        \"\"\"tf.data.Dataset: Returns a windowed dataset for testing.\"\"\"\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        \"\"\"Tuple of tf.Tensor: Returns an example batch of `inputs, labels` from the training dataset.\"\"\"\n",
    "        result = getattr(self, \"_example\", None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._example = result\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_window(train_df, val_df, test_df, days_in_past, width=24):\n",
    "    \"\"\"Generate a windowed dataset from train, validation, and test data.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training data.\n",
    "        val_df (pd.DataFrame): Validation data.\n",
    "        test_df (pd.DataFrame): Test data.\n",
    "        days_in_past (int): Number of days of past data to consider for predictions.\n",
    "        width (int, optional): Size of the prediction window. Defaults to 24.\n",
    "\n",
    "    Returns:\n",
    "        WindowGenerator: An instance of WindowGenerator configured with the provided data.\n",
    "    \"\"\"\n",
    "    OUT_STEPS = 24\n",
    "    multi_window = WindowGenerator(\n",
    "        input_width=width * days_in_past,\n",
    "        label_width=OUT_STEPS,\n",
    "        train_df=train_df,\n",
    "        val_df=val_df,\n",
    "        test_df=test_df,\n",
    "        shift=OUT_STEPS,\n",
    "    )\n",
    "    return multi_window"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(\n",
    "    train_data: pd.core.frame.DataFrame,\n",
    "    val_data: pd.core.frame.DataFrame,\n",
    "    test_data: pd.core.frame.DataFrame,\n",
    ") -> Tuple[\n",
    "    np.ndarray, np.ndarray, np.ndarray, pd.core.series.Series, pd.core.series.Series\n",
    "]:\n",
    "    \"\"\"Normalizes train, val and test splits.\n",
    "\n",
    "    Args:\n",
    "        train_data (pd.core.frame.DataFrame): Train split.\n",
    "        val_data (pd.core.frame.DataFrame): Validation split.\n",
    "        test_data (pd.core.frame.DataFrame): Test split.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Normalized splits with training mean and standard deviation.\n",
    "    \"\"\"\n",
    "    train_mean = train_data.mean()\n",
    "    train_std = train_data.std()\n",
    "\n",
    "    train_data = (train_data - train_mean) / train_std\n",
    "    val_data = (val_data - train_mean) / train_std\n",
    "    test_data = (test_data - train_mean) / train_std\n",
    "\n",
    "    return train_data, val_data, test_data, train_mean, train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model(num_features: int, days_in_past: int, out_steps = 24) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Constructs a Conv-LSTM model tailored for time series prediction.\n",
    "\n",
    "    This model predicts the next 24 hours based on the provided past days of data.\n",
    "    It leverages a 1D convolution layer to recognize local patterns and an LSTM\n",
    "    layer to understand long-term dependencies in the time series.\n",
    "\n",
    "    Parameters:\n",
    "    - num_features: The number of features (variables) in the dataset.\n",
    "    - days_in_past: Number of past days the model will consider for predictions.\n",
    "\n",
    "    Returns:\n",
    "    - A TensorFlow Keras model ready to be compiled and trained.\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    CONV_WIDTH = 3  # Width of the convolution filter.\n",
    "    OUT_STEPS = out_steps  # Number of prediction steps (next 24 hours).\n",
    "\n",
    "    # Constructing the Sequential model\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            # Masking layer: It ignores any input time step with a value of -1.0.\n",
    "            # This is useful for sequences of varying lengths or with missing values.\n",
    "            tf.keras.layers.Masking(mask_value=-1.0, input_shape=(days_in_past * 24, num_features)),\n",
    "\n",
    "            # Lambda layer: Slices the input sequence to consider only the last 'CONV_WIDTH' time steps.\n",
    "            # This reduces the sequence length to the most recent data before convolution.\n",
    "            tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "\n",
    "            # 1D Convolutional layer: Detects local patterns using a filter of width 'CONV_WIDTH'.\n",
    "            # It has 256 filters and uses the RELU activation function.\n",
    "            tf.keras.layers.Conv1D(256, activation=\"relu\", kernel_size=(CONV_WIDTH)),\n",
    "\n",
    "            # First Bidirectional LSTM layer: Captures long-term dependencies in both directions.\n",
    "            # It returns sequences, allowing the next LSTM layer to also operate over sequences.\n",
    "            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "\n",
    "            # Second Bidirectional LSTM layer: Captures more temporal dependencies.\n",
    "            # This does not return sequences, thus only providing the final output.\n",
    "            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=False)),\n",
    "\n",
    "            # Dense layer: A fully connected layer that outputs the predicted values for the next 24 hours.\n",
    "            # The 'kernel_initializer' ensures the initial weights of this layer are zeros.\n",
    "            tf.keras.layers.Dense(OUT_STEPS * 1, kernel_initializer=tf.initializers.zeros()),\n",
    "\n",
    "            # Reshape layer: Reshapes the output into the shape of [OUT_STEPS, 1].\n",
    "            # This ensures the model's output is 24 sequences of single values.\n",
    "            tf.keras.layers.Reshape([OUT_STEPS, 1]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compile_and_fit(\n",
    "    model: tf.keras.Model, window: WindowGenerator, patience: int = 2, Epochs: int = 20\n",
    ") -> tf.keras.callbacks.History:\n",
    "    \"\"\"\n",
    "    Compiles, trains, and applies early stopping to a TensorFlow Keras model.\n",
    "\n",
    "    The function sets deterministic seeds to ensure reproducibility. It uses\n",
    "    Mean Squared Error as the loss function and the Adam optimizer for training.\n",
    "    Early stopping is implemented based on the validation loss.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The TensorFlow Keras model to be compiled and trained.\n",
    "    - window: A windowed dataset, which contains both training and validation data.\n",
    "    - patience (optional): Number of epochs with no improvement in validation loss\n",
    "      after which training will be stopped. Default is 2.\n",
    "\n",
    "    Returns:\n",
    "    - The history of the training process.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the maximum number of epochs for training\n",
    "    EPOCHS = Epochs\n",
    "\n",
    "    # Set up early stopping based on validation loss\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=patience,\n",
    "        mode=\"min\"  # \"min\" indicates that training will stop when the monitored quantity stops decreasing\n",
    "    )\n",
    "\n",
    "    # Compile the model with Mean Squared Error as the loss and Adam as the optimizer\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "    )\n",
    "\n",
    "    # Seeds set for reproducibility across different runs\n",
    "    tf.random.set_seed(432)\n",
    "    np.random.seed(432)\n",
    "    random.seed(432)\n",
    "\n",
    "    # Train the model using the training data, while also validating with the validation data\n",
    "    history = model.fit(\n",
    "        window.train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=window.val,\n",
    "        callbacks=[early_stopping]  # Applying early stopping during training\n",
    "    )\n",
    "\n",
    "    # Notify the user if early stopping was triggered\n",
    "    if len(history.epoch) < EPOCHS:\n",
    "        print(\"\\nTraining stopped early to prevent overfitting, as the validation loss didn't improve for {} epochs.\".format(patience))\n",
    "\n",
    "    return history\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_conv_lstm_model(data, features, days_in_past):\n",
    "    \"\"\"\n",
    "    Trains a Conv-LSTM model on the provided time series dataset using specified features\n",
    "    and a defined historical window for forecasting the next 24 hours.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.core.frame.DataFrame): Time series dataset containing the data.\n",
    "        features (list[str]): List of feature columns to use from the dataset.\n",
    "        days_in_past (int): Number of past days to use for forecasting the subsequent 24-hour period.\n",
    "\n",
    "    Returns:\n",
    "        WindowGenerator: A windowed representation of the data used for training the model.\n",
    "        tf.keras.Model: The trained Conv-LSTM model.\n",
    "        DataSplits: A named tuple containing the training, validation, and test datasets along with\n",
    "                    their means and standard deviations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the provided data into training, validation, and test sets\n",
    "    data_splits = train_val_test_split(data[features])\n",
    "\n",
    "    # Extract the individual datasets and normalization parameters\n",
    "    train_data, val_data, test_data, train_mean, train_std = (\n",
    "        data_splits.train_data,\n",
    "        data_splits.val_data,\n",
    "        data_splits.test_data,\n",
    "        data_splits.train_mean,\n",
    "        data_splits.train_std,\n",
    "    )\n",
    "\n",
    "    # Generate a windowed representation of the data suitable for time series forecasting\n",
    "    window = generate_window(train_data, val_data, test_data, days_in_past)\n",
    "\n",
    "    # Determine the number of features in the windowed training dataset\n",
    "    num_features = window.train_df.shape[1]\n",
    "\n",
    "    # Create the Conv-LSTM model tailored to the data's feature count and the defined historical window size\n",
    "    model = create_model(num_features, days_in_past)\n",
    "\n",
    "    # Compile and train the model using the windowed data\n",
    "    history = compile_and_fit(model, window)\n",
    "\n",
    "    return window, model, data_splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
